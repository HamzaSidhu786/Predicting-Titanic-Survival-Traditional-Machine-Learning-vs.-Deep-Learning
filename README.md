<h1>Predicting Titanic Survival: Traditional Machine Learning vs. Deep Learning</h1>
<h2>Overview </h2>
In this project, we explore the classic Titanic dataset to predict passenger survival using both traditional machine-learning techniques and deep-learning models. We begin with data preprocessing and train a Gaussian Naive Bayes (GaussianNB) model. Then, we delve into feature engineering and data normalization before introducing the basics of deep learning using Keras. Finally, we compare the accuracy of the traditional machine learning approach with the deep learning model.

<h2>Data Preprocessing</h2>
We start by cleaning and preparing the dataset for analysis. This involves handling missing values, encoding categorical variables, and splitting the data into training and testing sets.

<h2>Traditional Machine Learning</h2>
<h3>Gaussian Naive Bayes</h3>
We train a Gaussian Naive Bayes classifier on the preprocessed data to predict survival probabilities based on various features.

<h2>Feature Engineering</h2>
We explore techniques to enhance model performance by creating or transforming existing features.

<h2>Data Normalization</h2>
Normalization ensures that all features have a similar scale, which aids in model convergence and performance.

<h2>Deep Learning with Keras</h2>
<h3>Introduction to Deep Learning</h3>
We provide a brief overview of deep learning concepts and the Keras library, emphasizing its simplicity and flexibility in building neural networks.

<h2>Model Training</h2>
Using Keras, we design a basic deep-learning model architecture and train it on the Titanic dataset.

<h2>Model Comparison</h2>
We evaluate the performance of the GaussianNB model and the deep learning model using appropriate evaluation metrics such as accuracy, precision, recall, and F1-score.

<h2>Conclusion</h2>
We conclude by discussing the strengths and limitations of both approaches and provide insights into when to choose traditional machine learning over deep learning and vice versa.


